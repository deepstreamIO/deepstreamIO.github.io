"use strict";(self.webpackChunkdeepstreamio_github_io=self.webpackChunkdeepstreamio_github_io||[]).push([[722],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return m}});var s=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);t&&(s=s.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,s)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,s,r=function(e,t){if(null==e)return{};var a,s,r={},n=Object.keys(e);for(s=0;s<n.length;s++)a=n[s],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(s=0;s<n.length;s++)a=n[s],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var i=s.createContext({}),c=function(e){var t=s.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=c(e.components);return s.createElement(i.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return s.createElement(s.Fragment,{},t)}},p=s.forwardRef((function(e,t){var a=e.components,r=e.mdxType,n=e.originalType,i=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=c(a),m=r,b=p["".concat(i,".").concat(m)]||p[m]||u[m]||n;return a?s.createElement(b,o(o({ref:t},d),{},{components:a})):s.createElement(b,o({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=a.length,o=new Array(n);o[0]=p;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var c=2;c<n;c++)o[c]=a[c];return s.createElement.apply(null,o)}return s.createElement.apply(null,a)}p.displayName="MDXCreateElement"},7067:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return i},metadata:function(){return c},toc:function(){return d},default:function(){return p}});var s=a(7462),r=a(3366),n=(a(7294),a(3905)),o=["components"],l={title:"Postgres DataBase Connector",tags:["postgres","postgresql","deepstream","realtime","search"]},i=void 0,c={unversionedId:"tutorials/plugins/database/postgres",id:"tutorials/plugins/database/postgres",title:"Postgres DataBase Connector",description:"What is Postgres?",source:"@site/docs/00-tutorials/60-plugins/30-database/10-postgres.md",sourceDirName:"00-tutorials/60-plugins/30-database",slug:"/tutorials/plugins/database/postgres",permalink:"/docs/tutorials/plugins/database/postgres",editUrl:"https://github.com/deepstreamIO/deepstreamIO.github.io/docs/00-tutorials/60-plugins/30-database/10-postgres.md",tags:[{label:"postgres",permalink:"/docs/tags/postgres"},{label:"postgresql",permalink:"/docs/tags/postgresql"},{label:"deepstream",permalink:"/docs/tags/deepstream"},{label:"realtime",permalink:"/docs/tags/realtime"},{label:"search",permalink:"/docs/tags/search"}],version:"current",sidebarPosition:10,frontMatter:{title:"Postgres DataBase Connector",tags:["postgres","postgresql","deepstream","realtime","search"]},sidebar:"tutorialSidebar",previous:{title:"Hazelcast Cache Connector",permalink:"/docs/tutorials/plugins/cache/hazelcast"},next:{title:"MongoDB DataBase Connector",permalink:"/docs/tutorials/plugins/database/mongodb"}},d=[{value:"What is Postgres?",id:"what-is-postgres",children:[],level:2},{value:"Why you should use Postgres as a database for deepstream",id:"why-you-should-use-postgres-as-a-database-for-deepstream",children:[],level:2},{value:"Why you should not use Postgres as a database for deepstream",id:"why-you-should-not-use-postgres-as-a-database-for-deepstream",children:[],level:2},{value:"How to use deepstream with Postgres",id:"how-to-use-deepstream-with-postgres",children:[],level:2},{value:"The API at a glance",id:"the-api-at-a-glance",children:[{value:"constructor(options)",id:"constructoroptions",children:[],level:3},{value:"destroy(callback)",id:"destroycallback",children:[],level:3},{value:"createSchema(name, callback)",id:"createschemaname-callback",children:[],level:3},{value:"destroySchema(name, callback)",id:"destroyschemaname-callback",children:[],level:3},{value:"getSchemaOverview(callback, name)",id:"getschemaoverviewcallback-name",children:[],level:3},{value:"subscribe(callback, done, schema)",id:"subscribecallback-done-schema",children:[],level:3},{value:"unsubscribe(callback, done, schema)",id:"unsubscribecallback-done-schema",children:[],level:3},{value:"set(key, version, value, callback)",id:"setkey-version-value-callback",children:[],level:3},{value:"get(key, callback)",id:"getkey-callback",children:[],level:3},{value:"delete(key, callback)",id:"deletekey-callback",children:[],level:3},{value:"query(statement, callback, args, silent)",id:"querystatement-callback-args-silent",children:[],level:3}],level:2}],u={toc:d};function p(e){var t=e.components,a=(0,r.Z)(e,o);return(0,n.kt)("wrapper",(0,s.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h2",{id:"what-is-postgres"},"What is Postgres?"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://www.postgresql.org/"},"PostgreSQL")," or Postgres for short is a relational database management system, similar to MySQL or Oracle. With development starting as early as 1986 and continuous improvement ever since it is as mature and established as databases go and has become one of the most solid and reliable cornerstones of the database world."),(0,n.kt)("p",null,"But that doesn\u2019t mean that Postgres is complicated or old fashioned. Over the years it has evolved from a simple relational database into a powerful data programming platform with elaborate stored procedures, trigger functions, a myriad of datatypes and powerful querying capabilities."),(0,n.kt)("h2",{id:"why-you-should-use-postgres-as-a-database-for-deepstream"},"Why you should use Postgres as a database for deepstream"),(0,n.kt)("p",null,"Postgres is established, reliable and rock solid. But it\u2019s especially its newer functionality that makes it a great fit for deepstream:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"It\u2019s support for binary JSON allows for efficient storage and searching of deepstream records"),(0,n.kt)("li",{parentName:"ul"},"It\u2019s built-in notification mechanism allows to run pub-sub and realtime events based on data-changes, a feature supported by ",(0,n.kt)("inlineCode",{parentName:"li"},"deepstream.io-storage-postgres")),(0,n.kt)("li",{parentName:"ul"},"It\u2019s extensively programmable in C, Python, Perl or Postgres own PL/pgSQL\n-It allows to automatically organize deepstream\u2019s data into tables created on the fly with very little overhead"),(0,n.kt)("li",{parentName:"ul"},"Combining triggers, jsonb-queries and notifications allows for the creation of realtime querying capabilities with streaming results")),(0,n.kt)("h2",{id:"why-you-should-not-use-postgres-as-a-database-for-deepstream"},"Why you should not use Postgres as a database for deepstream"),(0,n.kt)("p",null,"deepstream\u2019s data-structures are schemaless JSON documents identified by a unique key. This makes object-oriented databases a more natural fit as deepstream won\u2019t make much use of Postgres relational features. Beyond that, there\u2019s not much negative to say: Postgres is solid, fast and available from many hosting companies, e.g. ",(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com/rds/postgresql/"},"AWS")," or ",(0,n.kt)("a",{parentName:"p",href:"https://www.heroku.com/postgres"},"Heroku")," as well as under a very ",(0,n.kt)("a",{parentName:"p",href:"https://www.postgresql.org/about/licence/"},"permissive open source license")," - give it a go!"),(0,n.kt)("h2",{id:"how-to-use-deepstream-with-postgres"},"How to use deepstream with Postgres"),(0,n.kt)("p",null,"deepstream comes preinstalled with an official connector for postgres."),(0,n.kt)("p",null,"It can be configured in the ",(0,n.kt)("inlineCode",{parentName:"p"},"storage")," section of deepstreams ",(0,n.kt)("inlineCode",{parentName:"p"},"config.yml")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-yaml"},"storage:\n  name: postgres\n  options:\n    user: some-user\n    database: some-database\n    password: some-password\n    host: localhost\n    port: 5432 #postgres default post\n    schema: ds #schema defaults to ds. Will be created if it doesn't exist\n    defaultTable: default # default table name defaults to default\n    max: 10 #concurrent connections\n    idleTimeoutMillis: 30000 #timeout after which connection will be cut\n    writeInterval: 200 #amount of milliseconds during which writes will be buffered\n    useJsonb: false #store values as searchable binary JSON (slower)\n    notifications:\n      CREATE_TABLE: false #Get notified when tables are created\n      DESTROY_TABLE: false #Get notified when tables are dropped\n      INSERT: false # Get notified when records are created\n      UPDATE: false # Get notified when records are updated\n      DELETE: false # Get notified when records are deleted\n")),(0,n.kt)("p",null,"This connector can also be used as a standalone component from node.js to connect to postgres' notification mechanism. To do this, install the connector via"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"npm install @deepstream/storage-postgres --save\n#or\nyarn add @deepstream/storage-postgres\n")),(0,n.kt)("p",null,"and instantiate it directly"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-javascript"},"const { Connector } = require( '@deepstream/storage-postgres' );\nconst settings = {\n  user: process.env.PG_USER,\n  database: process.env.PG_DB,\n  password: process.env.PG_PASSWORD,\n  host: process.env.PG_HOST,\n  port: parseInt( process.env.PG_PORT, 10 )\n}\n\nconst connector = new Connector( settings )\n\n// start connector\nconnector.init()\n\nconnector.on( 'ready', ()=>{\n    connector.subscribe( event =>{\n        //event will be a map of event and table for CREATE_TABLE and DESTROY_TABLE\n        // { event: 'CREATE_TABLE', table: 'some-table' })\n        // or of event, table and key for INSERT, UPDATE AND DELETE, e.g.\n        // { event: 'INSERT', table: 'some-table', key: 'some-key' }\n    }, err => { if( err ) throw err; })\n\n    //subscriptions can be removed\n    connector.unsubscribe(( err )=>{ /* done */ })\n\n    // the connector also comes with a facility to get a map of all tables and the numbers of items within\n    connector.getSchemaOverview(( err, result ) => {\n        /* result will be e.g.\n        {\n            'some-table': 2,\n            'some-other-table': 1,\n            'new-table': 1,\n            'table-a': 2,\n            'table-b': 2\n        }\n        */\n    })\n})\n")),(0,n.kt)("h2",{id:"the-api-at-a-glance"},"The API at a glance"),(0,n.kt)("h3",{id:"constructoroptions"},"constructor(options)"),(0,n.kt)("p",null,"Create the Connector, see above for options"),(0,n.kt)("h3",{id:"destroycallback"},"destroy(callback)"),(0,n.kt)("p",null,"Destroy the connector. Callback will be invoked once complete"),(0,n.kt)("h3",{id:"createschemaname-callback"},"createSchema(name, callback)"),(0,n.kt)("p",null,"Create a new schema. The schema specified in the constructor options will be implicitly created. Default schema is 'ds'"),(0,n.kt)("h3",{id:"destroyschemaname-callback"},"destroySchema(name, callback)"),(0,n.kt)("p",null,"Destroys an existing schema"),(0,n.kt)("h3",{id:"getschemaoverviewcallback-name"},"getSchemaOverview(callback, name)"),(0,n.kt)("p",null,"Returns a map of tables to their number of rows (see above for example). Name is optional, if omitted, the schema from the options will be used"),(0,n.kt)("h3",{id:"subscribecallback-done-schema"},"subscribe(callback, done, schema)"),(0,n.kt)("p",null,"Subscribe to notifications from the schema. Which notifications you'll receive is determined by the ",(0,n.kt)("inlineCode",{parentName:"p"},"notifications")," option passed to the constructor. callback will be invoked with notifications in the format ",(0,n.kt)("inlineCode",{parentName:"p"},"{ event: 'INSERT', table: 'some-table', key: 'some-key' }"),", done will be called once the subscription is established. Schema is optional."),(0,n.kt)("h3",{id:"unsubscribecallback-done-schema"},"unsubscribe(callback, done, schema)"),(0,n.kt)("p",null,"Removes a previously registered callback or all listeners if callback is omitted. Schema is optional"),(0,n.kt)("h3",{id:"setkey-version-value-callback"},"set(key, version, value, callback)"),(0,n.kt)("p",null,"Writes a value to the database. If key includes a ",(0,n.kt)("inlineCode",{parentName:"p"},"/")," e.g. ",(0,n.kt)("inlineCode",{parentName:"p"},"cars/bmw"),", the first part will be used to create a table and the second part as id. Value can be any JSON blob, callback will be invoked once the write is complete. Please note that reads are buffered and batched and might not be executed straight away."),(0,n.kt)("h3",{id:"getkey-callback"},"get(key, callback)"),(0,n.kt)("p",null,"Retrieves a value from a database. Callback will be invoked with error or null, version and value. If record not found version will be -1."),(0,n.kt)("h3",{id:"deletekey-callback"},"delete(key, callback)"),(0,n.kt)("p",null,"Deletes a value from the database"),(0,n.kt)("h3",{id:"querystatement-callback-args-silent"},"query(statement, callback, args, silent)"),(0,n.kt)("p",null,"Low level query interface.  Statement is a PostgreSQL string, args an optional array of arguments for parameterized queries and silent = true ensures that errors are forwarded to the callback rather than thrown/logged."))}p.isMDXComponent=!0}}]);